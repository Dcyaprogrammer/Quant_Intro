{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lfKrhvAzzPPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6434f4bb-ad3b-4a45-87d6-8257e72affc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gymnasium\n",
        "%pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces"
      ],
      "metadata": {
        "id": "krFPmX_lzaEi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Env"
      ],
      "metadata": {
        "id": "KWnqppCdb8Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STBaseEnv(gym.Env):\n",
        "  def __init__(self, data, ibalance=1e4):\n",
        "    super(STBaseEnv, self).__init__()\n",
        "    self.data = data\n",
        "    self.ibalance = ibalance\n",
        "    self.action_space = spaces.Discrete(3)\n",
        "    self.balance = ibalance\n",
        "    self.current_step = 0\n",
        "    self.position = 0\n",
        "\n",
        "    # data.shape[1] is the num of features, 2 is for balance and position\n",
        "    self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1]+2))\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.balance = self.ibalance\n",
        "    self.position = 0\n",
        "    self.current_step =0\n",
        "\n",
        "    return self._get_observation()\n",
        "\n",
        "  def step(self, action):\n",
        "    obs = self._get_observation()\n",
        "    reward = 0  # calculate reward\n",
        "\n",
        "    # leave for implementation\n",
        "    if self.current_step == self.data.shape[0] - 1:\n",
        "      terminated = True\n",
        "    else:\n",
        "      terminated = False\n",
        "\n",
        "    # leave for implementation\n",
        "    truncated = False\n",
        "    info = self._get_info()\n",
        "\n",
        "    return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_observation(self):\n",
        "      obs = np.concatenate([self.data[self.current_step], [self.balance, self.position]])\n",
        "      return obs\n",
        "\n",
        "    def _get_info(self):\n",
        "      pass\n",
        "\n",
        "    def render(self):\n",
        "\n"
      ],
      "metadata": {
        "id": "8nMOORInzpWN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class STBaseEnv(gym.Env):\n",
        "  metadata = {'render_modes': ['human', 'rgb_array'], 'render_fps': 10} # 添加 rgb_array 模式\n",
        "\n",
        "  def __init__(self, data, ibalance=1e4, render_mode=None):\n",
        "    super(STBaseEnv, self).__init__()\n",
        "    self.data = data\n",
        "    self.ibalance = ibalance\n",
        "    self.action_space = spaces.Discrete(3) # 0: hold, 1: buy, 2: sell\n",
        "    self.balance = ibalance\n",
        "    self.current_step = 0\n",
        "    self.position = 0\n",
        "\n",
        "    self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1]+2), dtype=np.float32)\n",
        "\n",
        "    self.render_mode = render_mode\n",
        "    self.fig = None\n",
        "    self.ax = None\n",
        "    self.line_price = None\n",
        "    self.line_value = None\n",
        "    self.buy_scatter = None\n",
        "    self.sell_scatter = None\n",
        "\n",
        "    self.prices_history = []\n",
        "    self.total_value_history = []\n",
        "    self.buy_steps = []\n",
        "    self.sell_steps = []\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    super().reset(seed=seed)\n",
        "\n",
        "    self.balance = self.ibalance\n",
        "    self.position = 0\n",
        "    self.current_step = 0\n",
        "    self.prices_history = []\n",
        "    self.total_value_history = []\n",
        "    self.buy_steps = []\n",
        "    self.sell_steps = []\n",
        "\n",
        "    observation = self._get_observation()\n",
        "    info = self._get_info()\n",
        "    return observation, info\n",
        "\n",
        "  def step(self, action):\n",
        "    current_price = self.data[self.current_step, 0] # 假设第一个特征是价格\n",
        "    reward = 0\n",
        "\n",
        "    # 记录当前价格和总价值\n",
        "    self.prices_history.append(current_price)\n",
        "    self.total_value_history.append(self.balance + self.position * current_price)\n",
        "\n",
        "    # 交易逻辑和奖励计算\n",
        "    if action == 1: # Buy\n",
        "        if self.balance >= current_price:\n",
        "            self.position += 1\n",
        "            self.balance -= current_price\n",
        "            reward = 0.001 * (self.data[self.current_step+1, 0] - current_price) if self.current_step + 1 < self.data.shape[0] else 0 # 简单未来收益奖励\n",
        "            self.buy_steps.append(self.current_step)\n",
        "    elif action == 2: # Sell\n",
        "        if self.position >= 1:\n",
        "            self.position -= 1\n",
        "            self.balance += current_price\n",
        "            reward = 0.001 * (current_price - self.data[self.current_step+1, 0]) if self.current_step + 1 < self.data.shape[0] else 0 # 简单未来收益奖励\n",
        "            self.sell_steps.append(self.current_step)\n",
        "    else: # Hold\n",
        "        pass\n",
        "\n",
        "    self.current_step += 1\n",
        "\n",
        "    if self.current_step == self.data.shape[0] - 1:\n",
        "      terminated = True\n",
        "    else:\n",
        "      terminated = False\n",
        "\n",
        "    truncated = False\n",
        "    obs = self._get_observation()\n",
        "    info = self._get_info()\n",
        "\n",
        "    if self.render_mode == \"human\":\n",
        "        self.render()\n",
        "    elif self.render_mode == \"rgb_array\":\n",
        "        return self.render() # 返回图像数组\n",
        "\n",
        "    return obs, reward, terminated, truncated, info\n",
        "\n",
        "  def _get_observation(self):\n",
        "    if self.current_step >= self.data.shape[0]: # 确保不会越界\n",
        "        # 返回最后一个有效观测，或者处理结束状态\n",
        "        return np.concatenate([self.data[-1], [self.balance, self.position]])\n",
        "    return np.concatenate([self.data[self.current_step], [self.balance, self.position]])\n",
        "\n",
        "  def _get_info(self):\n",
        "    current_price = self.data[self.current_step, 0] if self.current_step < self.data.shape[0] else self.data[-1, 0] # 避免越界\n",
        "    total_value = self.balance + self.position * current_price\n",
        "    return {\"total_value\": total_value, \"balance\": self.balance, \"position\": self.position}\n",
        "\n",
        "  def render(self):\n",
        "    if self.render_mode is None:\n",
        "        return None\n",
        "\n",
        "    if self.fig is None:\n",
        "        self.fig, self.ax = plt.subplots(figsize=(12, 6))\n",
        "        self.line_price, = self.ax.plot([], [], label='Price')\n",
        "        self.line_value, = self.ax.plot([], [], label='Total Value', color='orange')\n",
        "        self.buy_scatter = self.ax.scatter([], [], color='green', marker='^', s=100, label='Buy')\n",
        "        self.sell_scatter = self.ax.scatter([], [], color='red', marker='v', s=100, label='Sell')\n",
        "        self.ax.legend()\n",
        "        self.ax.set_title('Trading Simulation')\n",
        "        self.ax.set_xlabel('Time Step')\n",
        "        self.ax.set_ylabel('Value')\n",
        "        self.ax.grid(True)\n",
        "        plt.ion() # Turn on interactive mode\n",
        "        plt.show()\n",
        "\n",
        "    # 更新数据\n",
        "    x_data = np.arange(len(self.prices_history))\n",
        "    self.line_price.set_data(x_data, self.prices_history)\n",
        "    self.line_value.set_data(x_data, self.total_value_history)\n",
        "\n",
        "    # 更新买入/卖出点\n",
        "    if self.buy_steps:\n",
        "        buy_x = np.array(self.buy_steps)\n",
        "        buy_y = np.array([self.prices_history[step] for step in self.buy_steps])\n",
        "        self.buy_scatter.set_offsets(np.c_[buy_x, buy_y])\n",
        "    if self.sell_steps:\n",
        "        sell_x = np.array(self.sell_steps)\n",
        "        sell_y = np.array([self.prices_history[step] for step in self.sell_steps])\n",
        "        self.sell_scatter.set_offsets(np.c_[sell_x, sell_y])\n",
        "\n",
        "    # 自动调整X轴范围\n",
        "    self.ax.set_xlim(0, max(self.current_step + 1, 10))\n",
        "\n",
        "    # 自动调整Y轴范围\n",
        "    min_val = min(min(self.prices_history) if self.prices_history else 0, min(self.total_value_history) if self.total_value_history else 0)\n",
        "    max_val = max(max(self.prices_history) if self.prices_history else 0, max(self.total_value_history) if self.total_value_history else 0)\n",
        "    self.ax.set_ylim(min_val * 0.9, max_val * 1.1)\n",
        "\n",
        "    self.fig.canvas.draw()\n",
        "    self.fig.canvas.flush_events()\n",
        "\n",
        "    if self.render_mode == \"rgb_array\":\n",
        "        # Capture the plot as an image array\n",
        "        self.fig.canvas.draw()\n",
        "        img = np.frombuffer(self.fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "        img = img.reshape(self.fig.canvas.get_width_height()[::-1] + (3,))\n",
        "        return img\n",
        "\n",
        "  def close(self):\n",
        "    if self.fig is not None:\n",
        "        plt.close(self.fig)\n",
        "        self.fig = None\n",
        "        self.ax = None\n",
        "\n",
        "# 示例使用\n",
        "if __name__ == \"__main__\":\n",
        "    # 生成更多数据点以便可视化效果更明显\n",
        "    prices = np.sin(np.linspace(0, 20, 200)) * 50 + 150 # 200个时间步\n",
        "    mock_data = prices.reshape(-1, 1)\n",
        "\n",
        "    # 测试 human 模式\n",
        "    env_human = STBaseEnv(data=mock_data, ibalance=10000, render_mode=\"human\")\n",
        "    obs, info = env_human.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    print(\"--- Starting Simulation (Matplotlib Human Render) ---\")\n",
        "    for _ in range(mock_data.shape[0] -1): # 运行到数据结束\n",
        "        action = np.random.randint(0, 3) # 随机行动\n",
        "        obs, reward, terminated, truncated, info = env_human.step(action)\n",
        "        total_reward += reward\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    env_human.close()\n",
        "    print(f\"\\n--- Simulation Finished (Human Render) ---\")\n",
        "    print(f\"Final Total Value: {info['total_value']:.2f}\")\n",
        "    print(f\"Total Reward: {total_reward:.2f}\")\n",
        "\n",
        "    # 测试 rgb_array 模式 (用于保存视频或集成到其他可视化工具)\n",
        "    # env_rgb = STBaseEnv(data=mock_data, ibalance=10000, render_mode=\"rgb_array\")\n",
        "    # obs, info = env_rgb.reset()\n",
        "    # frames = []\n",
        "    # done = False\n",
        "    # while not done:\n",
        "    #     action = np.random.randint(0, 3)\n",
        "    #     obs, reward, terminated, truncated, info = env_rgb.step(action)\n",
        "    #     frame = env_rgb.render()\n",
        "    #     if frame is not None:\n",
        "    #         frames.append(frame)\n",
        "    #     done = terminated or truncated\n",
        "    # env_rgb.close()\n",
        "    # print(f\"\\n--- Simulation Finished (RGB Array Render) ---\")\n",
        "    # print(f\"Collected {len(frames)} frames.\")\n",
        "    # # 你可以使用 imageio 或 moviepy 将这些帧保存为视频"
      ],
      "metadata": {
        "id": "kfZKDgNqukRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrappers"
      ],
      "metadata": {
        "id": "ki5Rr-Pwb-IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAIndicatorWrapper(gym.ObservationWrapper):\n",
        "  def __init__(self, env, window=5):\n",
        "    super(MAIndicatorWrapper, self).__init__(env)\n",
        "    self.window = window\n",
        "\n",
        "  def observation(self, observation):\n",
        "    ma = self.env.data[max(0, self.env.current_step-self.window+1):self.env.current_step+1, 0].mean()\n",
        "    return np.append(observation, ma)"
      ],
      "metadata": {
        "id": "4iJhrETNaqU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_PXbrVZcwkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}